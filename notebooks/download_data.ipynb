{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2 as pg\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    try:\n",
    "        conn = pg.connect(\n",
    "            dbname=\"current_flow_db\",\n",
    "            user=\"postgres\",\n",
    "            password=\"admin321\",\n",
    "            host=\"localhost\",\n",
    "            port=\"5432\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"I am unable to connect to the database\")\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = db_connect()\n",
    "cursor = db_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'carga_diaria' created successfully\n",
      "Table 'Etags' created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create tables in the database: carga_diaria and Etags.\n",
    "class CreateTables:\n",
    "    def __init__(self, connect_pg):\n",
    "        self.connect_pg = connect_pg\n",
    "        self.cursor = connect_pg.cursor()\n",
    "\n",
    "    def carga_diaria(self):\n",
    "        self.cursor.execute(\n",
    "            \"\"\"CREATE TABLE IF NOT EXISTS carga_diaria (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    id_subsistema VARCHAR NOT NULL,\n",
    "                    nom_subsistema VARCHAR NOT NULL,\n",
    "                    din_instante VARCHAR NOT NULL,\n",
    "                    val_cargaenergiamwmed VARCHAR,\n",
    "                    Ano INTEGER NOT NULL,\n",
    "                    input_file VARCHAR NOT NULL,\n",
    "                    CONSTRAINT unique_constraint_carga_diaria UNIQUE (id_subsistema, din_instante)\n",
    "            );\"\"\"\n",
    "        )\n",
    "        self.connect_pg.commit()\n",
    "        print(\"Table 'carga_diaria' created successfully\")\n",
    "\n",
    "    def Etags(self):\n",
    "        self.cursor.execute(\n",
    "            \"\"\"CREATE TABLE IF NOT EXISTS Etags (\n",
    "                URL TEXT PRIMARY KEY,\n",
    "                ETag TEXT\n",
    "            );\"\"\"\n",
    "        )\n",
    "        self.connect_pg.commit()\n",
    "        print(\"Table 'Etags' created successfully\")\n",
    "\n",
    "\n",
    "# Supondo que `connect_pg` seja uma conexão válida com o banco de dados PostgreSQL\n",
    "create_tables = CreateTables(connect_pg=db_connection)\n",
    "create_tables.carga_diaria()\n",
    "create_tables.Etags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for better readability\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to INFO or DEBUG for more verbose output\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(stream=sys.stdout),  # Log to console\n",
    "        # logging.FileHandler(\"file_downloads.log\"),  # Log to a file\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Function to load ETags from the database\n",
    "def load_etags_db():\n",
    "    cursor.execute(\"SELECT * FROM Etags\")  # Assuming `cursor` is a connected DB cursor\n",
    "    etags = cursor.fetchall()\n",
    "    etags_df = pd.DataFrame(etags, columns=[\"URL\", \"ETag\"])\n",
    "    logging.info(\"Loaded ETags from the database.\")\n",
    "    return etags_df\n",
    "\n",
    "\n",
    "# Function to get the ETag from a URL\n",
    "def get_etag(url):\n",
    "    try:\n",
    "        logging.info(f\"Fetching ETag for {url}\")\n",
    "        response = requests.head(f\"{url}\")\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        etag = response.headers.get(\"ETag\")\n",
    "        logging.info(f\"→ ETag fetched: {etag}\")\n",
    "        return etag\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch ETag for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to compare the current ETag with the stored ETag\n",
    "def compare_etag(url, new_etag):\n",
    "    previous_etag = etags_df[etags_df[\"URL\"] == url][\"ETag\"].values\n",
    "    return len(previous_etag) == 0 or previous_etag[0] != new_etag\n",
    "\n",
    "\n",
    "# Function to stage URLs for download if their ETag has changed\n",
    "def stage_etag(urls):\n",
    "    urls_to_update = []\n",
    "    logging.info(\"Checking for updates based on ETag comparison...\")\n",
    "    for url in urls:\n",
    "        etag = get_etag(url)\n",
    "        if etag and compare_etag(url, etag):\n",
    "            urls_to_update.append(url)\n",
    "            logging.info(f\"✔ URL staged for download: {url}\")\n",
    "        else:\n",
    "            logging.info(f\"✖ URL is up-to-date: {url}\")\n",
    "    return urls_to_update\n",
    "\n",
    "\n",
    "# Function to download the file from the URL and save it\n",
    "def download_file(url, save_dir=\"data/\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Starting download: {url}\")\n",
    "        response = requests.get(f\"{url}\")\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        file_path = os.path.join(save_dir, os.path.basename(url))\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        logging.info(f\"→ Download complete: {url} saved to {file_path}\")\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "\n",
    "# Function to update the database with new ETags\n",
    "def update_etag_db(url, new_etag):\n",
    "    try:\n",
    "        logging.info(f\"Updating ETag for {url} in the database.\")\n",
    "        # Check if the URL already exists in the database\n",
    "        cursor.execute(\"SELECT * FROM Etags WHERE URL = %s\", (url,))\n",
    "        result = cursor.fetchone()\n",
    "\n",
    "        if result:\n",
    "            # If URL exists, update the ETag\n",
    "            cursor.execute(\"UPDATE Etags SET ETag = %s WHERE URL = %s\", (new_etag, url))\n",
    "        else:\n",
    "            # If URL does not exist, insert a new row\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO Etags (URL, ETag) VALUES (%s, %s)\", (url, new_etag)\n",
    "            )\n",
    "\n",
    "        # Commit the transaction to save changes\n",
    "        db_connection.commit()\n",
    "        logging.info(f\"→ Database updated: ETag for {url}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to update ETag for {url} in the database: {e}\")\n",
    "        db_connection.rollback()  # Rollback in case of any issues\n",
    "\n",
    "\n",
    "# Function to process URLs: compare ETags, download if necessary, and update the DataFrame and database\n",
    "def process_urls(urls, save_dir=\"data/\"):\n",
    "    global etags_df\n",
    "\n",
    "    # Step 1: Stage URLs that need updating\n",
    "    urls_to_update = stage_etag(urls)\n",
    "\n",
    "    if urls_to_update:\n",
    "        logging.info(f\"URLs to be updated: {len(urls_to_update)} files\")\n",
    "\n",
    "        # Step 2: Download the files for the staged URLs\n",
    "        for url in urls_to_update:\n",
    "            logging.info(f\"--- Processing {url} ---\")\n",
    "            download_file(url, save_dir)\n",
    "\n",
    "            # Update the DataFrame with the new ETag after downloading\n",
    "            new_etag = get_etag(url)\n",
    "            if new_etag:\n",
    "                if not etags_df[etags_df[\"URL\"] == url].empty:\n",
    "                    etags_df.loc[etags_df[\"URL\"] == url, \"ETag\"] = new_etag\n",
    "                else:\n",
    "                    etags_df.loc[len(etags_df)] = [url, new_etag]\n",
    "\n",
    "                # Step 3: Update the ETag in the database\n",
    "                update_etag_db(url, new_etag)\n",
    "\n",
    "        logging.info(\n",
    "            \"All URLs have been processed. ETag DataFrame and database updated.\"\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\"No files need to be updated. All files are up-to-date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the API\n",
    "url_base = \"https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/\"\n",
    "\n",
    "# Define the range of years for which we want to fetch data\n",
    "years = range(2015, 2025)\n",
    "\n",
    "# Generate the list of URLs for each year\n",
    "urls = [f\"{url_base}CARGA_ENERGIA_{year}.csv\" for year in years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-22 17:56:20,745 [INFO] Loaded ETags from the database.\n",
      "2024-10-22 17:56:20,746 [INFO] Checking for updates based on ETag comparison...\n",
      "2024-10-22 17:56:20,746 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv\n",
      "2024-10-22 17:56:22,265 [INFO] → ETag fetched: \"2ef2d1ac377178d14bfa59e64dc578e3\"\n",
      "2024-10-22 17:56:22,265 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv\n",
      "2024-10-22 17:56:22,273 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv\n",
      "2024-10-22 17:56:23,205 [INFO] → ETag fetched: \"f2faf3fdd60276f2084235ea796f9d68\"\n",
      "2024-10-22 17:56:23,214 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv\n",
      "2024-10-22 17:56:23,216 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv\n",
      "2024-10-22 17:56:23,923 [INFO] → ETag fetched: \"69e7eab6ba21de9eef150628b78c5e45\"\n",
      "2024-10-22 17:56:23,925 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv\n",
      "2024-10-22 17:56:23,926 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv\n",
      "2024-10-22 17:56:24,578 [INFO] → ETag fetched: \"b3bf852dd993fccc37e9d639d6f518fa\"\n",
      "2024-10-22 17:56:24,581 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv\n",
      "2024-10-22 17:56:24,581 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv\n",
      "2024-10-22 17:56:25,530 [INFO] → ETag fetched: \"97a15c5091ddd7b366255b772a789cfb\"\n",
      "2024-10-22 17:56:25,533 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv\n",
      "2024-10-22 17:56:25,534 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv\n",
      "2024-10-22 17:56:26,568 [INFO] → ETag fetched: \"3fdb975298faa109c9a7008a786a2273\"\n",
      "2024-10-22 17:56:26,571 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv\n",
      "2024-10-22 17:56:26,571 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv\n",
      "2024-10-22 17:56:28,181 [INFO] → ETag fetched: \"9336ea5ca0861a1a4a5df3f78c9eeed6\"\n",
      "2024-10-22 17:56:28,195 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv\n",
      "2024-10-22 17:56:28,198 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv\n",
      "2024-10-22 17:56:29,266 [INFO] → ETag fetched: \"8923a92618dc772cf5938939a1c325c5\"\n",
      "2024-10-22 17:56:29,266 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv\n",
      "2024-10-22 17:56:29,266 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv\n",
      "2024-10-22 17:56:30,216 [INFO] → ETag fetched: \"f8e686719288d7ab2bca04519c849a12\"\n",
      "2024-10-22 17:56:30,218 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv\n",
      "2024-10-22 17:56:30,221 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv\n",
      "2024-10-22 17:56:31,443 [INFO] → ETag fetched: \"0db7d94c964fb588218594ce2f609a65\"\n",
      "2024-10-22 17:56:31,443 [INFO] ✔ URL staged for download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv\n",
      "2024-10-22 17:56:31,443 [INFO] URLs to be updated: 10 files\n",
      "2024-10-22 17:56:31,443 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv ---\n",
      "2024-10-22 17:56:31,459 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv\n",
      "2024-10-22 17:56:33,055 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv saved to data/CARGA_ENERGIA_2015.csv\n",
      "2024-10-22 17:56:33,058 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv\n",
      "2024-10-22 17:56:33,897 [INFO] → ETag fetched: \"2ef2d1ac377178d14bfa59e64dc578e3\"\n",
      "2024-10-22 17:56:33,914 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv in the database.\n",
      "2024-10-22 17:56:33,926 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2015.csv\n",
      "2024-10-22 17:56:33,930 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv ---\n",
      "2024-10-22 17:56:33,931 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv\n",
      "2024-10-22 17:56:35,208 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv saved to data/CARGA_ENERGIA_2016.csv\n",
      "2024-10-22 17:56:35,209 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv\n",
      "2024-10-22 17:56:36,829 [INFO] → ETag fetched: \"f2faf3fdd60276f2084235ea796f9d68\"\n",
      "2024-10-22 17:56:36,865 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv in the database.\n",
      "2024-10-22 17:56:36,874 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2016.csv\n",
      "2024-10-22 17:56:36,878 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv ---\n",
      "2024-10-22 17:56:36,878 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv\n",
      "2024-10-22 17:56:39,003 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv saved to data/CARGA_ENERGIA_2017.csv\n",
      "2024-10-22 17:56:39,003 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv\n",
      "2024-10-22 17:56:39,949 [INFO] → ETag fetched: \"69e7eab6ba21de9eef150628b78c5e45\"\n",
      "2024-10-22 17:56:39,953 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv in the database.\n",
      "2024-10-22 17:56:39,974 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2017.csv\n",
      "2024-10-22 17:56:39,979 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv ---\n",
      "2024-10-22 17:56:39,979 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv\n",
      "2024-10-22 17:56:41,525 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv saved to data/CARGA_ENERGIA_2018.csv\n",
      "2024-10-22 17:56:41,527 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv\n",
      "2024-10-22 17:56:42,379 [INFO] → ETag fetched: \"b3bf852dd993fccc37e9d639d6f518fa\"\n",
      "2024-10-22 17:56:42,386 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv in the database.\n",
      "2024-10-22 17:56:42,399 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2018.csv\n",
      "2024-10-22 17:56:42,399 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv ---\n",
      "2024-10-22 17:56:42,399 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv\n",
      "2024-10-22 17:56:44,397 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv saved to data/CARGA_ENERGIA_2019.csv\n",
      "2024-10-22 17:56:44,398 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv\n",
      "2024-10-22 17:56:45,462 [INFO] → ETag fetched: \"97a15c5091ddd7b366255b772a789cfb\"\n",
      "2024-10-22 17:56:45,462 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv in the database.\n",
      "2024-10-22 17:56:45,479 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2019.csv\n",
      "2024-10-22 17:56:45,479 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv ---\n",
      "2024-10-22 17:56:45,479 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv\n",
      "2024-10-22 17:56:47,627 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv saved to data/CARGA_ENERGIA_2020.csv\n",
      "2024-10-22 17:56:47,635 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv\n",
      "2024-10-22 17:56:48,589 [INFO] → ETag fetched: \"3fdb975298faa109c9a7008a786a2273\"\n",
      "2024-10-22 17:56:48,594 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv in the database.\n",
      "2024-10-22 17:56:48,611 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2020.csv\n",
      "2024-10-22 17:56:48,611 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv ---\n",
      "2024-10-22 17:56:48,611 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv\n",
      "2024-10-22 17:56:50,930 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv saved to data/CARGA_ENERGIA_2021.csv\n",
      "2024-10-22 17:56:50,931 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv\n",
      "2024-10-22 17:56:51,682 [INFO] → ETag fetched: \"9336ea5ca0861a1a4a5df3f78c9eeed6\"\n",
      "2024-10-22 17:56:51,689 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv in the database.\n",
      "2024-10-22 17:56:51,709 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2021.csv\n",
      "2024-10-22 17:56:51,709 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv ---\n",
      "2024-10-22 17:56:51,712 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv\n",
      "2024-10-22 17:56:53,015 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv saved to data/CARGA_ENERGIA_2022.csv\n",
      "2024-10-22 17:56:53,017 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv\n",
      "2024-10-22 17:56:53,752 [INFO] → ETag fetched: \"8923a92618dc772cf5938939a1c325c5\"\n",
      "2024-10-22 17:56:53,758 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv in the database.\n",
      "2024-10-22 17:56:53,768 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2022.csv\n",
      "2024-10-22 17:56:53,769 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv ---\n",
      "2024-10-22 17:56:53,769 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv\n",
      "2024-10-22 17:56:55,012 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv saved to data/CARGA_ENERGIA_2023.csv\n",
      "2024-10-22 17:56:55,019 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv\n",
      "2024-10-22 17:56:56,258 [INFO] → ETag fetched: \"f8e686719288d7ab2bca04519c849a12\"\n",
      "2024-10-22 17:56:56,262 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv in the database.\n",
      "2024-10-22 17:56:56,281 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2023.csv\n",
      "2024-10-22 17:56:56,281 [INFO] --- Processing https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv ---\n",
      "2024-10-22 17:56:56,281 [INFO] Starting download: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv\n",
      "2024-10-22 17:56:58,378 [INFO] → Download complete: https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv saved to data/CARGA_ENERGIA_2024.csv\n",
      "2024-10-22 17:56:58,378 [INFO] Fetching ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv\n",
      "2024-10-22 17:56:59,346 [INFO] → ETag fetched: \"0db7d94c964fb588218594ce2f609a65\"\n",
      "2024-10-22 17:56:59,346 [INFO] Updating ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv in the database.\n",
      "2024-10-22 17:56:59,367 [INFO] → Database updated: ETag for https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/CARGA_ENERGIA_2024.csv\n",
      "2024-10-22 17:56:59,367 [INFO] All URLs have been processed. ETag DataFrame and database updated.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DataFrame by loading ETags from the database\n",
    "etags_df = load_etags_db()\n",
    "\n",
    "# Example usage\n",
    "process_urls(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-22 17:57:31,060 [INFO] Processing files in directory: ./data/\n",
      "2024-10-22 17:57:31,060 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2015.csv\n",
      "2024-10-22 17:57:31,109 [INFO] File ./data/CARGA_ENERGIA_2015.csv read successfully with 1460 rows.\n",
      "2024-10-22 17:57:31,116 [INFO] Loading data from CARGA_ENERGIA_2015.csv into the database.\n",
      "2024-10-22 17:57:31,116 [INFO] Deleting existing rows for CARGA_ENERGIA_2015.csv from the database.\n",
      "2024-10-22 17:57:31,127 [INFO] → Rows for CARGA_ENERGIA_2015.csv deleted successfully.\n",
      "2024-10-22 17:57:31,127 [INFO] Inserting new rows for CARGA_ENERGIA_2015.csv into the database.\n",
      "2024-10-22 17:57:32,924 [INFO] → Rows for CARGA_ENERGIA_2015.csv inserted successfully.\n",
      "2024-10-22 17:57:32,925 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2016.csv\n",
      "2024-10-22 17:57:32,943 [INFO] File ./data/CARGA_ENERGIA_2016.csv read successfully with 1464 rows.\n",
      "2024-10-22 17:57:32,943 [INFO] Loading data from CARGA_ENERGIA_2016.csv into the database.\n",
      "2024-10-22 17:57:32,943 [INFO] Deleting existing rows for CARGA_ENERGIA_2016.csv from the database.\n",
      "2024-10-22 17:57:32,951 [INFO] → Rows for CARGA_ENERGIA_2016.csv deleted successfully.\n",
      "2024-10-22 17:57:32,951 [INFO] Inserting new rows for CARGA_ENERGIA_2016.csv into the database.\n",
      "2024-10-22 17:57:34,603 [INFO] → Rows for CARGA_ENERGIA_2016.csv inserted successfully.\n",
      "2024-10-22 17:57:34,604 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2017.csv\n",
      "2024-10-22 17:57:34,620 [INFO] File ./data/CARGA_ENERGIA_2017.csv read successfully with 1460 rows.\n",
      "2024-10-22 17:57:34,620 [INFO] Loading data from CARGA_ENERGIA_2017.csv into the database.\n",
      "2024-10-22 17:57:34,620 [INFO] Deleting existing rows for CARGA_ENERGIA_2017.csv from the database.\n",
      "2024-10-22 17:57:34,629 [INFO] → Rows for CARGA_ENERGIA_2017.csv deleted successfully.\n",
      "2024-10-22 17:57:34,630 [INFO] Inserting new rows for CARGA_ENERGIA_2017.csv into the database.\n",
      "2024-10-22 17:57:36,496 [INFO] → Rows for CARGA_ENERGIA_2017.csv inserted successfully.\n",
      "2024-10-22 17:57:36,496 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2018.csv\n",
      "2024-10-22 17:57:36,509 [INFO] File ./data/CARGA_ENERGIA_2018.csv read successfully with 1460 rows.\n",
      "2024-10-22 17:57:36,512 [INFO] Loading data from CARGA_ENERGIA_2018.csv into the database.\n",
      "2024-10-22 17:57:36,512 [INFO] Deleting existing rows for CARGA_ENERGIA_2018.csv from the database.\n",
      "2024-10-22 17:57:36,512 [INFO] → Rows for CARGA_ENERGIA_2018.csv deleted successfully.\n",
      "2024-10-22 17:57:36,521 [INFO] Inserting new rows for CARGA_ENERGIA_2018.csv into the database.\n",
      "2024-10-22 17:57:38,031 [INFO] → Rows for CARGA_ENERGIA_2018.csv inserted successfully.\n",
      "2024-10-22 17:57:38,031 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2019.csv\n",
      "2024-10-22 17:57:38,047 [INFO] File ./data/CARGA_ENERGIA_2019.csv read successfully with 1460 rows.\n",
      "2024-10-22 17:57:38,047 [INFO] Loading data from CARGA_ENERGIA_2019.csv into the database.\n",
      "2024-10-22 17:57:38,047 [INFO] Deleting existing rows for CARGA_ENERGIA_2019.csv from the database.\n",
      "2024-10-22 17:57:38,055 [INFO] → Rows for CARGA_ENERGIA_2019.csv deleted successfully.\n",
      "2024-10-22 17:57:38,055 [INFO] Inserting new rows for CARGA_ENERGIA_2019.csv into the database.\n",
      "2024-10-22 17:57:39,534 [INFO] → Rows for CARGA_ENERGIA_2019.csv inserted successfully.\n",
      "2024-10-22 17:57:39,534 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2020.csv\n",
      "2024-10-22 17:57:39,539 [INFO] File ./data/CARGA_ENERGIA_2020.csv read successfully with 1464 rows.\n",
      "2024-10-22 17:57:39,539 [INFO] Loading data from CARGA_ENERGIA_2020.csv into the database.\n",
      "2024-10-22 17:57:39,539 [INFO] Deleting existing rows for CARGA_ENERGIA_2020.csv from the database.\n",
      "2024-10-22 17:57:39,563 [INFO] → Rows for CARGA_ENERGIA_2020.csv deleted successfully.\n",
      "2024-10-22 17:57:39,564 [INFO] Inserting new rows for CARGA_ENERGIA_2020.csv into the database.\n",
      "2024-10-22 17:57:40,871 [INFO] → Rows for CARGA_ENERGIA_2020.csv inserted successfully.\n",
      "2024-10-22 17:57:40,871 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2021.csv\n",
      "2024-10-22 17:57:40,887 [INFO] File ./data/CARGA_ENERGIA_2021.csv read successfully with 1460 rows.\n",
      "2024-10-22 17:57:40,887 [INFO] Loading data from CARGA_ENERGIA_2021.csv into the database.\n",
      "2024-10-22 17:57:40,894 [INFO] Deleting existing rows for CARGA_ENERGIA_2021.csv from the database.\n",
      "2024-10-22 17:57:40,898 [INFO] → Rows for CARGA_ENERGIA_2021.csv deleted successfully.\n",
      "2024-10-22 17:57:40,901 [INFO] Inserting new rows for CARGA_ENERGIA_2021.csv into the database.\n",
      "2024-10-22 17:57:42,441 [INFO] → Rows for CARGA_ENERGIA_2021.csv inserted successfully.\n",
      "2024-10-22 17:57:42,441 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2022.csv\n",
      "2024-10-22 17:57:42,458 [INFO] File ./data/CARGA_ENERGIA_2022.csv read successfully with 1460 rows.\n",
      "2024-10-22 17:57:42,462 [INFO] Loading data from CARGA_ENERGIA_2022.csv into the database.\n",
      "2024-10-22 17:57:42,462 [INFO] Deleting existing rows for CARGA_ENERGIA_2022.csv from the database.\n",
      "2024-10-22 17:57:42,470 [INFO] → Rows for CARGA_ENERGIA_2022.csv deleted successfully.\n",
      "2024-10-22 17:57:42,470 [INFO] Inserting new rows for CARGA_ENERGIA_2022.csv into the database.\n",
      "2024-10-22 17:57:43,808 [INFO] → Rows for CARGA_ENERGIA_2022.csv inserted successfully.\n",
      "2024-10-22 17:57:43,821 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2023.csv\n",
      "2024-10-22 17:57:43,831 [INFO] File ./data/CARGA_ENERGIA_2023.csv read successfully with 1460 rows.\n",
      "2024-10-22 17:57:43,836 [INFO] Loading data from CARGA_ENERGIA_2023.csv into the database.\n",
      "2024-10-22 17:57:43,836 [INFO] Deleting existing rows for CARGA_ENERGIA_2023.csv from the database.\n",
      "2024-10-22 17:57:43,845 [INFO] → Rows for CARGA_ENERGIA_2023.csv deleted successfully.\n",
      "2024-10-22 17:57:43,845 [INFO] Inserting new rows for CARGA_ENERGIA_2023.csv into the database.\n",
      "2024-10-22 17:57:45,231 [INFO] → Rows for CARGA_ENERGIA_2023.csv inserted successfully.\n",
      "2024-10-22 17:57:45,231 [INFO] Reading CSV file: ./data/CARGA_ENERGIA_2024.csv\n",
      "2024-10-22 17:57:45,247 [INFO] File ./data/CARGA_ENERGIA_2024.csv read successfully with 1176 rows.\n",
      "2024-10-22 17:57:45,251 [INFO] Loading data from CARGA_ENERGIA_2024.csv into the database.\n",
      "2024-10-22 17:57:45,251 [INFO] Deleting existing rows for CARGA_ENERGIA_2024.csv from the database.\n",
      "2024-10-22 17:57:45,259 [INFO] → Rows for CARGA_ENERGIA_2024.csv deleted successfully.\n",
      "2024-10-22 17:57:45,259 [INFO] Inserting new rows for CARGA_ENERGIA_2024.csv into the database.\n",
      "2024-10-22 17:57:46,491 [INFO] → Rows for CARGA_ENERGIA_2024.csv inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "# Function to read downloaded CSV files into pandas DataFrames\n",
    "def read_csv_file(file_path):\n",
    "    try:\n",
    "        logging.info(f\"Reading CSV file: {file_path}\")\n",
    "        df = pd.read_csv(file_path, sep=\";\", decimal=\",\")\n",
    "        logging.info(f\"File {file_path} read successfully with {len(df)} rows.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to delete existing rows for the file from the `carga_diaria` table\n",
    "def delete_existing_rows(input_file):\n",
    "    try:\n",
    "        logging.info(f\"Deleting existing rows for {input_file} from the database.\")\n",
    "        delete_query = \"DELETE FROM carga_diaria WHERE input_file = %s;\"\n",
    "        cursor.execute(delete_query, (input_file,))\n",
    "        db_connection.commit()\n",
    "        logging.info(f\"→ Rows for {input_file} deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to delete rows for {input_file}: {e}\")\n",
    "        db_connection.rollback()\n",
    "\n",
    "\n",
    "# Function to insert all rows from the DataFrame into the `carga_diaria` table\n",
    "def insert_file_to_db(df, input_file):\n",
    "    try:\n",
    "        logging.info(f\"Inserting new rows for {input_file} into the database.\")\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO carga_diaria (id_subsistema, nom_subsistema, din_instante, val_cargaenergiamwmed, Ano, input_file)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        data_to_insert = [\n",
    "            (\n",
    "                row[\"id_subsistema\"],\n",
    "                row[\"nom_subsistema\"],\n",
    "                row[\"din_instante\"],\n",
    "                row[\"val_cargaenergiamwmed\"],\n",
    "                row[\"Ano\"],\n",
    "                input_file,\n",
    "            )\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        logging.info(f\"→ Rows for {input_file} inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to insert rows for {input_file}: {e}\")\n",
    "        db_connection.rollback()\n",
    "\n",
    "\n",
    "# Function to load data from a file into the database\n",
    "def load_file_to_db(df, input_file):\n",
    "    logging.info(f\"Loading data from {input_file} into the database.\")\n",
    "    # Step 1: Delete existing rows for this file\n",
    "    delete_existing_rows(input_file)\n",
    "    # Step 2: Insert the new data from the file\n",
    "    insert_file_to_db(df, input_file)\n",
    "\n",
    "\n",
    "# Main function to process all downloaded files and load them into the database\n",
    "def process_and_load_files(file_dir=\"data/\"):\n",
    "    logging.info(f\"Processing files in directory: {file_dir}\")\n",
    "    for file_name in os.listdir(file_dir):\n",
    "        file_path = os.path.join(file_dir, file_name)\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            df = read_csv_file(file_path)\n",
    "            if df is not None:\n",
    "                # Add the year based on the file name\n",
    "                year = int(file_name.split(\"_\")[-1].replace(\".csv\", \"\"))\n",
    "                df[\"Ano\"] = year\n",
    "                df[\"input_file\"] = file_name\n",
    "                # Load the data into the database (delete old rows, insert new ones)\n",
    "                load_file_to_db(df, file_name)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_and_load_files(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "carga_diaria\n",
      "etags\n"
     ]
    }
   ],
   "source": [
    "# Connect to the PostgreSQL database\n",
    "conn = db_connect()\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a query to list all tables in the public schema\n",
    "cur.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all results\n",
    "tables = cur.fetchall()\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"Tables in the database:\")\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "def execute_query(query):\n",
    "    try:\n",
    "        cur = db_connection.cursor()\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchall()\n",
    "        cur.close()\n",
    "        columns = [desc[0] for desc in cur.description]\n",
    "        return pd.DataFrame(result, columns=columns)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to execute query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_subsistema</th>\n",
       "      <th>nom_subsistema</th>\n",
       "      <th>din_instante</th>\n",
       "      <th>val_cargaenergiamwmed</th>\n",
       "      <th>ano</th>\n",
       "      <th>input_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Norte</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4541.00516667</td>\n",
       "      <td>2015</td>\n",
       "      <td>CARGA_ENERGIA_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NE</td>\n",
       "      <td>Nordeste</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>8308.52194932</td>\n",
       "      <td>2015</td>\n",
       "      <td>CARGA_ENERGIA_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>Sul</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>7717.62003968</td>\n",
       "      <td>2015</td>\n",
       "      <td>CARGA_ENERGIA_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SE</td>\n",
       "      <td>Sudeste/Centro-Oeste</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>30874.77870833</td>\n",
       "      <td>2015</td>\n",
       "      <td>CARGA_ENERGIA_2015.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>Norte</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>4886.83425000</td>\n",
       "      <td>2015</td>\n",
       "      <td>CARGA_ENERGIA_2015.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id id_subsistema        nom_subsistema din_instante val_cargaenergiamwmed  \\\n",
       "0   1             N                 Norte   2015-01-01         4541.00516667   \n",
       "1   2            NE              Nordeste   2015-01-01         8308.52194932   \n",
       "2   3             S                   Sul   2015-01-01         7717.62003968   \n",
       "3   4            SE  Sudeste/Centro-Oeste   2015-01-01        30874.77870833   \n",
       "4   5             N                 Norte   2015-01-02         4886.83425000   \n",
       "\n",
       "    ano              input_file  \n",
       "0  2015  CARGA_ENERGIA_2015.csv  \n",
       "1  2015  CARGA_ENERGIA_2015.csv  \n",
       "2  2015  CARGA_ENERGIA_2015.csv  \n",
       "3  2015  CARGA_ENERGIA_2015.csv  \n",
       "4  2015  CARGA_ENERGIA_2015.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"SELECT * FROM carga_diaria LIMIT 5;\"\n",
    "\n",
    "result = execute_query(query)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
