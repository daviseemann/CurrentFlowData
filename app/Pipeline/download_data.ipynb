{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2 as pg\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    try:\n",
    "        conn = pg.connect(\n",
    "            dbname=\"current_flow_db\",\n",
    "            user=\"postgres\",\n",
    "            password=\"admin321\",\n",
    "            host=\"localhost\",\n",
    "            port=\"5432\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"I am unable to connect to the database\")\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = db_connect()\n",
    "cursor = db_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'carga_diaria' created successfully\n",
      "Table 'Etags' created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create tables in the database: carga_diaria and Etags.\n",
    "class CreateTables:\n",
    "    def __init__(self, connect_pg):\n",
    "        self.connect_pg = connect_pg\n",
    "        self.cursor = connect_pg.cursor()\n",
    "\n",
    "    def carga_diaria(self):\n",
    "        self.cursor.execute(\n",
    "            \"\"\"CREATE TABLE IF NOT EXISTS carga_diaria (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    id_subsistema VARCHAR NOT NULL,\n",
    "                    nom_subsistema VARCHAR NOT NULL,\n",
    "                    din_instante VARCHAR NOT NULL,\n",
    "                    val_cargaenergiamwmed VARCHAR,\n",
    "                    Ano INTEGER NOT NULL,\n",
    "                    input_file VARCHAR NOT NULL,\n",
    "                    CONSTRAINT unique_constraint_carga_diaria UNIQUE (id_subsistema, din_instante)\n",
    "            );\"\"\"\n",
    "        )\n",
    "        self.connect_pg.commit()\n",
    "        print(\"Table 'carga_diaria' created successfully\")\n",
    "\n",
    "    def Etags(self):\n",
    "        self.cursor.execute(\n",
    "            \"\"\"CREATE TABLE IF NOT EXISTS Etags (\n",
    "                URL TEXT PRIMARY KEY,\n",
    "                ETag TEXT\n",
    "            );\"\"\"\n",
    "        )\n",
    "        self.connect_pg.commit()\n",
    "        print(\"Table 'Etags' created successfully\")\n",
    "\n",
    "\n",
    "# Supondo que `connect_pg` seja uma conexão válida com o banco de dados PostgreSQL\n",
    "create_tables = CreateTables(connect_pg=db_connection)\n",
    "create_tables.carga_diaria()\n",
    "create_tables.Etags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for better readability\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set to INFO or DEBUG for more verbose output\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(stream=sys.stdout),  # Log to console\n",
    "        logging.FileHandler(\"file_downloads.log\"),  # Log to a file\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Function to load ETags from the database\n",
    "def load_etags_db():\n",
    "    cursor.execute(\"SELECT * FROM Etags\")  # Assuming `cursor` is a connected DB cursor\n",
    "    etags = cursor.fetchall()\n",
    "    etags_df = pd.DataFrame(etags, columns=[\"URL\", \"ETag\"])\n",
    "    logging.info(\"Loaded ETags from the database.\")\n",
    "    return etags_df\n",
    "\n",
    "\n",
    "# Function to get the ETag from a URL\n",
    "def get_etag(url):\n",
    "    try:\n",
    "        logging.info(f\"Fetching ETag for {url}\")\n",
    "        response = requests.head(f\"{url}\")\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        etag = response.headers.get(\"ETag\")\n",
    "        logging.info(f\"→ ETag fetched: {etag}\")\n",
    "        return etag\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch ETag for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to compare the current ETag with the stored ETag\n",
    "def compare_etag(url, new_etag):\n",
    "    previous_etag = etags_df[etags_df[\"URL\"] == url][\"ETag\"].values\n",
    "    return len(previous_etag) == 0 or previous_etag[0] != new_etag\n",
    "\n",
    "\n",
    "# Function to stage URLs for download if their ETag has changed\n",
    "def stage_etag(urls):\n",
    "    urls_to_update = []\n",
    "    logging.info(\"Checking for updates based on ETag comparison...\")\n",
    "    for url in urls:\n",
    "        etag = get_etag(url)\n",
    "        if etag and compare_etag(url, etag):\n",
    "            urls_to_update.append(url)\n",
    "            logging.info(f\"✔ URL staged for download: {url}\")\n",
    "        else:\n",
    "            logging.info(f\"✖ URL is up-to-date: {url}\")\n",
    "    return urls_to_update\n",
    "\n",
    "\n",
    "# Function to download the file from the URL and save it\n",
    "def download_file(url, save_dir=\"data/\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Starting download: {url}\")\n",
    "        response = requests.get(f\"{url}\")\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        file_path = os.path.join(save_dir, os.path.basename(url))\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        logging.info(f\"→ Download complete: {url} saved to {file_path}\")\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "\n",
    "# Function to update the database with new ETags\n",
    "def update_etag_db(url, new_etag):\n",
    "    try:\n",
    "        logging.info(f\"Updating ETag for {url} in the database.\")\n",
    "        # Check if the URL already exists in the database\n",
    "        cursor.execute(\"SELECT * FROM Etags WHERE URL = %s\", (url,))\n",
    "        result = cursor.fetchone()\n",
    "\n",
    "        if result:\n",
    "            # If URL exists, update the ETag\n",
    "            cursor.execute(\"UPDATE Etags SET ETag = %s WHERE URL = %s\", (new_etag, url))\n",
    "        else:\n",
    "            # If URL does not exist, insert a new row\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO Etags (URL, ETag) VALUES (%s, %s)\", (url, new_etag)\n",
    "            )\n",
    "\n",
    "        # Commit the transaction to save changes\n",
    "        db_connection.commit()\n",
    "        logging.info(f\"→ Database updated: ETag for {url}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to update ETag for {url} in the database: {e}\")\n",
    "        db_connection.rollback()  # Rollback in case of any issues\n",
    "\n",
    "\n",
    "# Function to process URLs: compare ETags, download if necessary, and update the DataFrame and database\n",
    "def process_urls(urls, save_dir=\"data/\"):\n",
    "    global etags_df\n",
    "\n",
    "    # Step 1: Stage URLs that need updating\n",
    "    urls_to_update = stage_etag(urls)\n",
    "\n",
    "    if urls_to_update:\n",
    "        logging.info(f\"URLs to be updated: {len(urls_to_update)} files\")\n",
    "\n",
    "        # Step 2: Download the files for the staged URLs\n",
    "        for url in urls_to_update:\n",
    "            logging.info(f\"--- Processing {url} ---\")\n",
    "            download_file(url, save_dir)\n",
    "\n",
    "            # Update the DataFrame with the new ETag after downloading\n",
    "            new_etag = get_etag(url)\n",
    "            if new_etag:\n",
    "                if not etags_df[etags_df[\"URL\"] == url].empty:\n",
    "                    etags_df.loc[etags_df[\"URL\"] == url, \"ETag\"] = new_etag\n",
    "                else:\n",
    "                    etags_df.loc[len(etags_df)] = [url, new_etag]\n",
    "\n",
    "                # Step 3: Update the ETag in the database\n",
    "                update_etag_db(url, new_etag)\n",
    "\n",
    "        logging.info(\n",
    "            \"All URLs have been processed. ETag DataFrame and database updated.\"\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\"No files need to be updated. All files are up-to-date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the API\n",
    "url_base = \"https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/carga_energia_di/\"\n",
    "\n",
    "# Define the range of years for which we want to fetch data\n",
    "years = range(2015, 2025)\n",
    "\n",
    "# Generate the list of URLs for each year\n",
    "urls = [f\"{url_base}CARGA_ENERGIA_{year}.csv\" for year in years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame by loading ETags from the database\n",
    "etags_df = load_etags_db()\n",
    "\n",
    "# Example usage\n",
    "process_urls(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "# Function to read downloaded CSV files into pandas DataFrames\n",
    "def read_csv_file(file_path):\n",
    "    try:\n",
    "        logging.info(f\"Reading CSV file: {file_path}\")\n",
    "        df = pd.read_csv(file_path, sep=\";\", decimal=\",\")\n",
    "        logging.info(f\"File {file_path} read successfully with {len(df)} rows.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to delete existing rows for the file from the `carga_diaria` table\n",
    "def delete_existing_rows(input_file):\n",
    "    try:\n",
    "        logging.info(f\"Deleting existing rows for {input_file} from the database.\")\n",
    "        delete_query = \"DELETE FROM carga_diaria WHERE input_file = %s;\"\n",
    "        cursor.execute(delete_query, (input_file,))\n",
    "        db_connection.commit()\n",
    "        logging.info(f\"→ Rows for {input_file} deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to delete rows for {input_file}: {e}\")\n",
    "        db_connection.rollback()\n",
    "\n",
    "\n",
    "# Function to insert all rows from the DataFrame into the `carga_diaria` table\n",
    "def insert_file_to_db(df, input_file):\n",
    "    try:\n",
    "        logging.info(f\"Inserting new rows for {input_file} into the database.\")\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO carga_diaria (id_subsistema, nom_subsistema, din_instante, val_cargaenergiamwmed, Ano, input_file)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        data_to_insert = [\n",
    "            (\n",
    "                row[\"id_subsistema\"],\n",
    "                row[\"nom_subsistema\"],\n",
    "                row[\"din_instante\"],\n",
    "                row[\"val_cargaenergiamwmed\"],\n",
    "                row[\"Ano\"],\n",
    "                input_file,\n",
    "            )\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "        db_connection.commit()\n",
    "        logging.info(f\"→ Rows for {input_file} inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to insert rows for {input_file}: {e}\")\n",
    "        db_connection.rollback()\n",
    "\n",
    "\n",
    "# Function to load data from a file into the database\n",
    "def load_file_to_db(df, input_file):\n",
    "    logging.info(f\"Loading data from {input_file} into the database.\")\n",
    "    # Step 1: Delete existing rows for this file\n",
    "    delete_existing_rows(input_file)\n",
    "    # Step 2: Insert the new data from the file\n",
    "    insert_file_to_db(df, input_file)\n",
    "\n",
    "\n",
    "# Main function to process all downloaded files and load them into the database\n",
    "def process_and_load_files(file_dir=\"data/\"):\n",
    "    logging.info(f\"Processing files in directory: {file_dir}\")\n",
    "    for file_name in os.listdir(file_dir):\n",
    "        file_path = os.path.join(file_dir, file_name)\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            df = read_csv_file(file_path)\n",
    "            if df is not None:\n",
    "                # Add the year based on the file name\n",
    "                year = int(file_name.split(\"_\")[-1].replace(\".csv\", \"\"))\n",
    "                df[\"Ano\"] = year\n",
    "                df[\"input_file\"] = file_name\n",
    "                # Load the data into the database (delete old rows, insert new ones)\n",
    "                load_file_to_db(df, file_name)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_and_load_files(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
